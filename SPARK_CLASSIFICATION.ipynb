{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-RmvWsXQyhu",
        "outputId": "e27df3c2-8429-465c-af2d-223b7ca106ee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iF29l_UDQo6x"
      },
      "outputs": [],
      "source": [
        "## IMPORTING NECESSARY LIBRARIES\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, PCA, StringIndexer, StandardScaler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, NaiveBayes\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CREATING SPARK SESSION\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"PySparkClassification\").getOrCreate()"
      ],
      "metadata": {
        "id": "r47zis2GRDcz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LOADING THE IRIS DATASET\n",
        "iris = load_iris()\n"
      ],
      "metadata": {
        "id": "i6ZoLHMQRE3d"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SEPARATING INTO FEATURE AND TARGET VARIABLE\n",
        "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "iris_df['target'] = iris.target\n"
      ],
      "metadata": {
        "id": "oJHxYINRREz2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CONVERTING THE PANDAS DATAFRAME TO A PYSPARK DATAFRAME\n",
        "df = spark.createDataFrame(iris_df)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmKjZvdqREyC",
        "outputId": "15861090-67f8-4294-cce3-257bc435225e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+-----------------+----------------+------+\n",
            "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|target|\n",
            "+-----------------+----------------+-----------------+----------------+------+\n",
            "|              5.1|             3.5|              1.4|             0.2|     0|\n",
            "|              4.9|             3.0|              1.4|             0.2|     0|\n",
            "|              4.7|             3.2|              1.3|             0.2|     0|\n",
            "|              4.6|             3.1|              1.5|             0.2|     0|\n",
            "|              5.0|             3.6|              1.4|             0.2|     0|\n",
            "+-----------------+----------------+-----------------+----------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DROPPING THE MISSING ROWS\n",
        "df = df.na.drop()"
      ],
      "metadata": {
        "id": "pKD9D5ZMXWUe"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CONVERTING THE TARGET COLUMN FROM CATEGORICAL TO NUMERIC(CONTINUOUS)\n",
        "indexer = StringIndexer(inputCol=\"target\", outputCol=\"indexed_target\")\n",
        "\n",
        "df = indexer.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "uSAD4088VttS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ASSEMBLING THE FEATURES TO A SINGLE VECTOR COLUMN\n",
        "assembler = VectorAssembler(inputCols=iris.feature_names, outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8CLsfVjREvf",
        "outputId": "0d2d1399-09b1-4b17-d814-3f91ccc7ca4a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+-----------------+----------------+------+--------------+-----------------+\n",
            "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|target|indexed_target|         features|\n",
            "+-----------------+----------------+-----------------+----------------+------+--------------+-----------------+\n",
            "|              5.1|             3.5|              1.4|             0.2|     0|           0.0|[5.1,3.5,1.4,0.2]|\n",
            "|              4.9|             3.0|              1.4|             0.2|     0|           0.0|[4.9,3.0,1.4,0.2]|\n",
            "|              4.7|             3.2|              1.3|             0.2|     0|           0.0|[4.7,3.2,1.3,0.2]|\n",
            "|              4.6|             3.1|              1.5|             0.2|     0|           0.0|[4.6,3.1,1.5,0.2]|\n",
            "|              5.0|             3.6|              1.4|             0.2|     0|           0.0|[5.0,3.6,1.4,0.2]|\n",
            "+-----------------+----------------+-----------------+----------------+------+--------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## APPLYING PCA TO REDUCE DIMENSION\n",
        "pca = PCA(k=2, inputCol=\"features\", outputCol=\"pca_features\")\n",
        "pca_model = pca.fit(df)\n",
        "df_pca = pca_model.transform(df)\n",
        "df_pca.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg8vlPuyREsv",
        "outputId": "dd02f2af-1995-435e-ef61-7532d533a13a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+-----------------+----------------+------+--------------+-----------------+--------------------+\n",
            "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|target|indexed_target|         features|        pca_features|\n",
            "+-----------------+----------------+-----------------+----------------+------+--------------+-----------------+--------------------+\n",
            "|              5.1|             3.5|              1.4|             0.2|     0|           0.0|[5.1,3.5,1.4,0.2]|[-2.8182395066394...|\n",
            "|              4.9|             3.0|              1.4|             0.2|     0|           0.0|[4.9,3.0,1.4,0.2]|[-2.7882234453146...|\n",
            "|              4.7|             3.2|              1.3|             0.2|     0|           0.0|[4.7,3.2,1.3,0.2]|[-2.6133745635497...|\n",
            "|              4.6|             3.1|              1.5|             0.2|     0|           0.0|[4.6,3.1,1.5,0.2]|[-2.7570222769675...|\n",
            "|              5.0|             3.6|              1.4|             0.2|     0|           0.0|[5.0,3.6,1.4,0.2]|[-2.7736485960544...|\n",
            "+-----------------+----------------+-----------------+----------------+------+--------------+-----------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## SPLITTING THE DATA INTO TRAIN AND TEST DATA\n",
        "train_data, test_data = df_pca.randomSplit([0.8, 0.2], seed=1234)\n"
      ],
      "metadata": {
        "id": "j-zX1j9XREp9"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DEFINING AND TRAINING THE DECISION TREE CLASSIFIER MODEL AND PREDICTING ON TEST DATA\n",
        "dt_classifier = DecisionTreeClassifier(labelCol=\"indexed_target\", featuresCol=\"pca_features\")\n",
        "\n",
        "dt_model = dt_classifier.fit(train_data)\n",
        "\n",
        "dt_predictions = dt_model.transform(test_data)"
      ],
      "metadata": {
        "id": "RRtcNzc_REnb"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DECISION TREE MODEL EVALUATION AND TEST ACCURACY\n",
        "dt_evaluator = MulticlassClassificationEvaluator(labelCol=\"indexed_target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "dt_accuracy = dt_evaluator.evaluate(dt_predictions)\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", dt_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2E0DXVOREkx",
        "outputId": "2114bf80-045e-4f54-9501-0e67f9319cda"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.972972972972973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DEFINING AND TRAINING THE RANDOM FOREST CLASSIFIER MODEL AND PREDICTING ON TEST DATA\n",
        "rf_classifier = RandomForestClassifier(labelCol=\"indexed_target\", featuresCol=\"pca_features\")\n",
        "\n",
        "rf_model = rf_classifier.fit(train_data)\n",
        "\n",
        "rf_predictions = rf_model.transform(test_data)"
      ],
      "metadata": {
        "id": "0Rs1qsWsREiP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## RANDOM FOREST CALSSIFIER MODEL EVALUATION AND TEST ACCURACY\n",
        "rf_accuracy = dt_evaluator.evaluate(rf_predictions)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3WZkkOYREfe",
        "outputId": "5620c22d-e456-448d-f720-6f6c5027185c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.972972972972973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TERMINATING THE SPARK SESSION\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "PbkDZtK2YyCq"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}